{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d51af-a6da-4c80-8dba-af386adc2b83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the dotenv library to read environment variable overrides from the .env file.\n",
    "# Then define and initialize variables from this config. \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pysrc.services.config_service import ConfigService \n",
    "\n",
    "load_dotenv(override=True)\n",
    "print('load_dotenv completed')\n",
    "\n",
    "aoai_endpoint = ConfigService.azure_openai_url()\n",
    "aoai_api_key = ConfigService.azure_openai_key()\n",
    "aoai_completions_depl = ConfigService.azure_openai_completions_deployment()\n",
    "aoai_embeddings_depl = ConfigService.azure_openai_embeddings_deployment()\n",
    "mongo_vcore_conn_str = ConfigService.mongo_vcore_conn_str()\n",
    "graph_source_db = ConfigService.graph_source_db()\n",
    "documents_container = ConfigService.documents_container()\n",
    "mem_container_name = 'mem1'\n",
    "\n",
    "print('aoai_endpoint:  {}'.format(aoai_endpoint))\n",
    "print('aoai_api_key:   {}'.format(aoai_api_key))\n",
    "print('aoai_completions_depl: {}'.format(aoai_completions_depl))\n",
    "print('aoai_embeddings_depl:  {}'.format(aoai_embeddings_depl))\n",
    "print('mongo_vcore_conn_str:  {}'.format(mongo_vcore_conn_str))\n",
    "print('graph_source_db:       {}'.format(graph_source_db))\n",
    "print('documents_container:   {}'.format(documents_container))\n",
    "print('mem_container_name:    {}'.format(mem_container_name))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46cfb1-9cf4-4ce4-b2b4-cf06f5b60352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm local file IO with class FS\n",
    "\n",
    "from pysrc.util.fs import FS\n",
    "\n",
    "infile = 'requirements.in'\n",
    "lines = FS.read_lines(infile)\n",
    "print('{} lines read from file {}'.format(len(lines), infile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c12c6e-766a-4c81-b8b6-d509c52042ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Helper Functions\n",
    "\n",
    "import json\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.memory.memory_store_base import MemoryStoreBase\n",
    "\n",
    "async def upsert_data_to_memory_store(\n",
    "    memory: SemanticTextMemory, store: MemoryStoreBase, data_file_path: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    This asynchronous function takes two memory stores and a data file path as arguments.\n",
    "    It is designed to upsert (update or insert) data into the memory stores from the data file.\n",
    "\n",
    "    Args:\n",
    "        kernel_memory_store (callable): A callable object that represents the kernel memory store where data will be upserted.\n",
    "        memory_store (callable): A callable object that represents the memory store where data will be upserted.\n",
    "        data_file_path (str): The path to the data file that contains the data to be upserted.\n",
    "\n",
    "    Returns:\n",
    "        None. The function performs an operation that modifies the memory stores in-place.\n",
    "    \"\"\"\n",
    "    with open(file=data_file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        n = 0\n",
    "        for item in data:\n",
    "            n += 1\n",
    "            # check if the item already exists in the memory store\n",
    "            # if the id doesn't exist, it throws an exception\n",
    "            try:\n",
    "                already_created = bool(\n",
    "                    await store.get(\n",
    "                        mem_container_name, item[\"id\"], with_embedding=True\n",
    "                    )\n",
    "                )\n",
    "            except Exception:\n",
    "                already_created = False\n",
    "\n",
    "            # if the record doesn't exist, we generate embeddings and save it to the database\n",
    "            if not already_created:\n",
    "                await memory.save_information(\n",
    "                    collection=mem_container_name,\n",
    "                    id=item[\"id\"],\n",
    "                    # the embedding is generated from the text field\n",
    "                    text=item[\"content\"],\n",
    "                    description=item[\"title\"],\n",
    "                )\n",
    "                print(\n",
    "                    \"Generating embeddings and saving new item:\",\n",
    "                    n,\n",
    "                    \"/\",\n",
    "                    len(data),\n",
    "                    end=\"\\r\",\n",
    "                )\n",
    "            else:\n",
    "                print(\"Skipping item already exits:\", n, \"/\", len(data), end=\"\\r\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa40fce-d80c-4560-bd72-0eaa4608101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Semantic Kernel and the chat_completion and text_embedding services\n",
    "# within the kernel\n",
    "\n",
    "import semantic_kernel as sk\n",
    "\n",
    "from pysrc.services.config_service import ConfigService \n",
    "\n",
    "# Intialize the kernel\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")\n",
    "\n",
    "# Adding chat_completion service (AzureChatCompletion)\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"chat_completion\",\n",
    "        deployment_name=aoai_completions_depl,\n",
    "        endpoint=aoai_endpoint,\n",
    "        api_key=aoai_api_key\n",
    "    )\n",
    ")\n",
    "print(\"Added Azure OpenAI Chat Service...\")\n",
    "\n",
    "# Adding text_embedding service (AzureTextEmbedding)\n",
    "kernel.add_service(\n",
    "    AzureTextEmbedding(\n",
    "        service_id=\"text_embedding\",\n",
    "        deployment_name=aoai_embeddings_depl,\n",
    "        endpoint=aoai_endpoint,\n",
    "        api_key=aoai_api_key\n",
    "    )\n",
    ")\n",
    "print(\"Added Azure OpenAI Embedding Generation Service...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb9775-2d7a-413e-aae3-d5cff0ab3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure AzureCosmosDBMemoryStore\n",
    "\n",
    "collection_name = documents_container\n",
    "\n",
    "# Vector search index parameters\n",
    "index_name = \"vectorSearchIndex\"\n",
    "vector_dimensions = (\n",
    "    1536  # text-embedding-ada-002 uses a 1536-dimensional embedding vector\n",
    ")\n",
    "num_lists = 20\n",
    "similarity = \"COS\"  # cosine distance\n",
    "cosmos_api = \"mongo-vcore\"\n",
    "\n",
    "from semantic_kernel.connectors.memory.azure_cosmosdb import (\n",
    "    AzureCosmosDBMemoryStore,\n",
    ")\n",
    "\n",
    "# aoai_endpoint = ConfigService.azure_openai_url()\n",
    "# aoai_api_key = ConfigService.azure_openai_key()\n",
    "# aoai_completions_depl = ConfigService.azure_openai_completions_deployment()\n",
    "# aoai_embeddings_depl = ConfigService.azure_openai_embeddings_deployment()\n",
    "# mongo_vcore_conn_str = ConfigService.mongo_vcore_conn_str()\n",
    "# graph_source_db = ConfigService.graph_source_db()\n",
    "# documents_container = ConfigService.documents_container()\n",
    "# mem_container_name = 'mem1'\n",
    "\n",
    "# db.runCommand({\n",
    "#   createIndexes: 'mem1',\n",
    "#   indexes: [\n",
    "#     {\n",
    "#       name: 'vectorSearchIndex',\n",
    "#       key: {\n",
    "#         \"embeddings\": \"cosmosSearch\"\n",
    "#       },\n",
    "#       cosmosSearchOptions: {\n",
    "#         kind: 'vector-ivf',\n",
    "#         numLists: 20,\n",
    "#         similarity: 'COS',\n",
    "#         dimensions: 1536\n",
    "#       }\n",
    "#     }\n",
    "#   ]\n",
    "# });\n",
    "\n",
    "print(\"Creating or updating Azure Cosmos DB Memory Store...\")\n",
    "# create azure cosmos db for mongo db vcore api store and collection with vector ivf\n",
    "# currently, semantic kernel only supports the ivf vector kind\n",
    "store = await AzureCosmosDBMemoryStore.create(\n",
    "    cosmos_connstr=mongo_vcore_conn_str,\n",
    "    cosmos_api=cosmos_api,\n",
    "    database_name=graph_source_db,\n",
    "    collection_name=mem_container_name,\n",
    "    index_name=index_name,\n",
    "    vector_dimensions=vector_dimensions,\n",
    "    num_lists=num_lists,\n",
    "    similarity=similarity\n",
    ")\n",
    "print(\"Finished updating Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c42864-424c-4e73-87b8-458767117797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the created memory store to the semantic kernel instance.\n",
    "\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "\n",
    "memory = SemanticTextMemory(storage=store, embeddings_generator=kernel.get_service(\"text_embedding\"))\n",
    "kernel.import_plugin_from_object(TextMemoryPlugin(memory), \"TextMemoryPluginACDB\")\n",
    "print(\"Registered Azure Cosmos DB Memory Store...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde16cfb-66ca-4763-a28f-eaca865e2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to the memory store\n",
    "\n",
    "print(\"Upserting data to Azure Cosmos DB Memory Store...\")\n",
    "await upsert_data_to_memory_store(memory, store, \"./data/text-sample.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4acca38-2f7b-48b8-abae-cd1b0acfdfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Vector DB\n",
    "\n",
    "# each time it calls the embedding model to generate embeddings from your query\n",
    "query_term = \"What is Azure Database for Managed Instances?\"\n",
    "result = await memory.search(mem_container_name, query_term)\n",
    "\n",
    "print(\n",
    "    f\"Result is: {result[0].text}\\nRelevance Score: {result[0].relevance}\\nFull Record: {result[0].additional_metadata}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838dcdd-c500-4e3c-a15f-a8fcaad4c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string prompt\n",
    "\n",
    "prompt = \"\"\"\n",
    "    You are a chatbot that can have a conversations about any topic related to the provided context.\n",
    "    Give explicit answers from the provided context or say 'I don't know' if it does not have an answer.\n",
    "    provided context: {{$db_record}}\n",
    "\n",
    "    User: {{$query_term}}\n",
    "    Chatbot:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cbc805-fffa-4309-a7d4-40f06b33ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OpenAITextPromptExecutionSettings\n",
    "\n",
    "import semantic_kernel.connectors.ai.open_ai as sk_oai\n",
    "\n",
    "execution_settings = sk_oai.OpenAITextPromptExecutionSettings(\n",
    "   service_id=\"chat_completion\",\n",
    "    ai_model_id=aoai_completions_depl,\n",
    "    max_tokens=500,\n",
    "    temperature=0.0,\n",
    "    top_p=0.5\n",
    ")\n",
    "\n",
    "print('OpenAITextPromptExecutionSettings created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2764eb-333b-4ae7-9bed-03231cc3d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PromptTemplateConfig\n",
    "\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "\n",
    "chat_prompt_template_config = sk.PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"grounded_response\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"db_record\", description=\"The database record\", is_required=True),\n",
    "        InputVariable(name=\"query_term\", description=\"The user input\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=execution_settings\n",
    ")\n",
    "print('PromptTemplateConfig created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a98f74f-3a6b-4837-a1a2-2dc5df764441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat function\n",
    "\n",
    "chat_function = kernel.create_function_from_prompt(\n",
    "    prompt=prompt,\n",
    " function_name= \"ChatGPTFunc2\", plugin_name=\"chatGPTPlugin2\", prompt_template_config=chat_prompt_template_config\n",
    ")\n",
    "print('chat function created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbca20a-4786-444f-8acb-1da5fe7be7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completions_result = await kernel.invoke(chat_function, sk.KernelArguments(query_term=query_term, db_record=result[0].additional_metadata))\n",
    "\n",
    "print(completions_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f02c92-4e6a-488e-9e5c-24a2af9410e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce255f-c5dc-4214-bbc4-c46c78bb11de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361c011-5fa8-4355-9ecf-76b21dbeff87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c313e20-2b35-4dba-87a8-be7626646f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "3bc80dd1-59b1-4307-9479-4a32d01fb6bf",
   "metadata": {},
   "source": [
    "\n",
    "import time\n",
    "\n",
    "query_term = \"\"\n",
    "while query_term != \"exit\":\n",
    "    query_term = input(\"Enter a query: \")\n",
    "    result = await memory.search(collection_name, query_term)\n",
    "    completions_result = kernel.invoke_stream(chat_function, sk.KernelArguments(query_term=query_term, db_record=result[0].additional_metadata))\n",
    "    print(f\"Question:\\n{query_term}\\nResponse:\")\n",
    "    async for completion in completions_result:\n",
    "        print(str(completion[0]), end=\"\")\n",
    "    print(\"\\n\")\n",
    "    time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2eabaa-f24a-4b22-9654-fe7251e8ea0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
